TODO
- Connecting to C code using read/write handlers
- Parallelism
- GC of dead channels (and threads)?
- Type system?

IO/primitives
- No types for now (many complications!)
- u64, u64 math, "match" works on u64 as well as channels
- IO can be done with channels that read/write u64
  - e.g. cat = !stdin(c).stdout<c>.0
    - send/recv never inspect the values so it's fine
    - stdin/stdout will correctly format their results/inputs
- Currently have new x; P
  One way to add in IO/primitives:
  - foreign { C code } -> x; P
    Run C code to compute a value and send it to x, then continue as P
  - foreign y <- x { C code }; P
    Read y from x and run C code that uses it, then continue as P
  Then, for example, can have:
  - new stdin stdout;
    all {
      loop foreign c <- stdout { fputc(c, stdout); }.
      loop foreign { return fgetc(stdin); } -> stdin.
    }
  But now this might block forever b/c fgetc isn't async.
- Ideally:
  - y -> x ==> maybe can run C code that uses y on receiving end
  - y <- x ==> maybe triggers some C code that sends y back
- Another way to add IO/primitives:
  - Can declare, at global scope, channel x as foreign
    - Channels are either "foreign read handler", "foreign write handler", or neither
    - Can define C code handling read/write "events" (again at global scope)
    - e.g. handling writes to stdout: foreign c -> stdout { fputc(c, stdout); }
    - e.g. handling reads from stdin: foreign <- stdin { return fgetc(stdin); }
  - Implementation: handlers get their own threads (so that they have enough
    stack space to execute), initialized at startup.
  - Handlers basically run the handling code in a loop.
  - e.g. adding two numbers:
      x <- stdin_int;
      y <- stdin_int;
      new xy; // For private communication with adder
      xy -> adder;
      x -> xy;
      y -> xy;
      result <- xy;
      result -> stdout_int.
  - Handler impls:
    foreign ch -> adder {
      gt_write(ch, (gt_ch)((uint64_t)gt_read(ch) + (uint64_t)gt_read(ch)));
    }
    foreign <- stdin_int {
      int c;
      scanf("%d", &c);
      return (gt_ch)c;
    }
    foreign c -> stdout_int {
      printf("%d", (int)c);
    }
  - This compiles to global channels and wires up handlers properly:
      gt_ch adder;
      gt_ch stdin_int;
      gt_ch stdout_int;
      void adder_handler(gt_ch ch) {
        gt_write(ch, (gt_ch)((uint64_t)gt_read(ch) + (uint64_t)gt_read(ch)));
      }
      void adder_loop(void) { for (;;) adder_handler(gt_read(adder)); }
      gt_ch stdin_int_handler(void) {
        int c;
        scanf("%d", &c);
        return (gt_ch)c;
      }
      void stdin_int_loop(void) { for (;;) gt_write(stdin_int, stdin_int_handler()); }
      void stdout_int_handler(gt_ch c) {
        printf("%d", (int)c);
      }
      void stdout_int_loop(void) { for (;;) stdout_int_handler(gt_read(stdout_int)); }
    Then later, in main:
      adder = gt_chan();
      stdin_int = gt_chan();
      stdout_int = gt_chan();
      gt_go(adder_loop, 0x10000);
      gt_go(stdin_int_loop, 0x10000);
      gt_go(stdout_int_loop, 0x10000);
  - To prevent scanf from blocking everything else, can force stdin_int's ring buffer
    to be really small. So only a few characters can be read in at a time before
    stdin_int_loop has to take a break and let other threads process what was read in.
    - Customizing ring buffers for individual channels?
    - This would make C channels that read from stdin in a loop less blocky
    - But maybe this will Just Work after implementing parallelism
  - fgetc still blocks, so this is basically just a more restrictive version of the
    previous "inline C" idea.
    - Before, both pi calc threads and C code could read from the same channel. Now certain
      ends of channels are permanently marked as foreign and can only be handled by a
      single C handler.
  - This is probably fine? If you want both C code and pi calc threads to read from
    a channel ch, can write:
      foreign x -> ch' { ... }
      loop x <- ch; x -> ch'.
    i.e. a single process occasionally can steal stuff from ch and forward it on to ch',
    which the single C handler can read from. All other pi calc threads can still use
    ch as before, but now occasionally this forwarding thread will win and send a value
    off to C land.
    Likewise, if you want both C code and pi calc threads to write to ch, can write:
      foreign <- ch' { ... }
      loop x <- ch'; x -> ch.
    All pi calc threads can still write to/read from ch as before, but now occasionally
    the forwarding loop will win, read a value from C land through ch', and send it to ch.
  - This way the pi calc and non pi calc worlds are nicely separated and there's a way to
    unseparate them if really needed.

Compilation
- FV for liveness analysis
  - Loops complicate this a bit
- Register allocation using global register variables
- Spill into C locals
- gt_go_alloca(void f(void), size_t m, size_t n)
  - Use to pass spilled free variables on to forked processes
  - Max stack size n
  - Local stack size m for initial stack frame of f i.e. initial stack is
      &f
      .
      .   m bytes
      .
      &gt_stop
  - f must (add $m, %rsp) before ret

Liveness
- Before using FV as basis for liveness function, want to make it a bit more precise
  - e.g. new x, new y, send x to z, send y to z, halt
    - FV(send x to z, send y to z, halt) = {x, y, z} ==> x, y, z interfere with each other
    - But ideally, x and y should get the same register
- Solution: float new down to the most precise location
  - x not in FV(P) ==> new x, P ~~> P ("dead variable elimination")
  - new x, new y, P ~~> new y, new x, P
  - x not in {y, z} ==> new x, send y to z, P ~~> send y to z, new x, P
  - x != z ==> new x, read y from z, P ~~> read y from z, new x, P (x != y by UB)
  - x not in FV(P) ==> new x, P | Q ~~> P | (new x, Q)
  - x not in FV(Q) ==> new x, P | Q ~~> (new x, P) | Q
  - new x, P + Q ~~> (new x, P) + (new x, Q)
  - x not in {y, z1, .., zn} ==>
    new x, match y {z1 -> P1; ..; zn -> Pn} ~~>
    match y {z1 -> new x, P1; ..; zn -> new x, Pn}
- In some cases, new x, loop P ~~> loop new x, P
  - Depends if new x, P can rewrite to something a lot more favorable

Register allocation 
- Slightly different from usual allocation, because the cost of spilling is different.
- "Spilling" just means the variable becomes a C variable instead of a global register
  variable. So a spilled variable will probably still get put into a register and doesn't
  necessarily cost more to work with.
- The cost of spilled variables is that they have to be manually shuttled across forks:
  - e.g. suppose {x spills, y in rbx} in new x, P | send x to y
  - Then this compiles to
      void f(void) {
        void *rsp = gt_self()->rsp;
        send(rbx, ((gt_t *)rsp)[0]);
        asm("add 16, %%rsp\t\n" : : : "rsp");
      }
           .
           .
           .
      gt_ch x = gt_chan();
      gt_t q = gt_go_alloca(f, 16, MAX_STACK_SIZE);
      ((gt_ch *)q->rsp)[1] = x; // spilled x
      q->rbx = rbx;
      rest of P
  - Now suppose {x in r12, y in rbx} in new x, P | send x to y
  - Then this compiles to
      void f(void) { send(rbx, r12); }
           .
           .
           .
      rbx = gt_chan();
      gt_go(f, MAX_STACK_SIZE);
      q->rbx = rbx;
      q->r12 = r12;
      rest of P

Register allocation for P with variables x₁ .. xₙ
- Registers R represented as natural numbers
- Sort x₁ .. xₙ in increasing order of spillability to get y₁ .. yₙ
- Find largest i s.t. F(i) SAT and assign y₁ .. yᵢ accordingly, where
  - F(i) = C ∧ /\ y ∈ R for y in y₁ .. yᵢ
  - C = /\ distinct(FV(P')) for each subprocess P' of P
- Find smallest j s.t. G(j) SAT and assign yᵢ₊₁ .. yₙ accordingly, where
  - G(j) = C ∧ /\ y ∈ {1 .. j} for y in yᵢ₊₁ .. yₙ

Computing spillability of a variable x if there are no loops or matches:
- Spillability is just 0 - the expected number of forks that happen in x's lifetime
- forks(x, 0)
  || forks(x, "new _, P")
  || forks(x, "read _ from _, P")
  || forks(x, "send _ to _, P") = forks(x, P)
- forks(x, P | Q) = (x in FV(Q)) + forks(x, P) + forks(x, Q)
- forks(x, P + Q) = 1/2 forks(x, P) + 1/2 forks(x, Q)

Spillability of x if there are loops (but not matches):
- Loops "run forever" but could technically "wait forever" because reads/writes wait
- For now, simple heuristic: forks(x, loop P) = k forks(x, P) for some big k
  - Assume loops fork much more than non-loops
  - Assume n > m ==> loop with n forks always worse than loop with m forks

Spillability of x if there are matches:
- Unlike (+), matches probably won't choose subprocesses uniformly at random
- For now, simple heuristic:
  - forks(x, match y {_ -> P₁; ..; _ -> Pₙ}) = max forks(x, Pᵢ) for i in {1 .. n}
  - Always assume the worst

